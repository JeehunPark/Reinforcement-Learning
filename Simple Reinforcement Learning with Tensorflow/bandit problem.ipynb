{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bandit problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밴딧의 손잡이 목록 작성\n",
    "bandit_arms = [0.2, 0, -1.2, 0.3, -1.0]\n",
    "num_arms = len(bandit_arms)\n",
    "\n",
    "def pullBandit(bandit):\n",
    "    result = np.random.randn(1)\n",
    "    if result > bandit:\n",
    "        # 양의 보상 반환\n",
    "        return 1\n",
    "    else:\n",
    "        # 음의 보상 반환\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 구현\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 네트워크의 피드포워드 부분을 구현한다.\n",
    "weights = tf.Variable(tf.ones([num_arms]))\n",
    "output = tf.nn.softmax(weights)\n",
    "\n",
    "# 학습과정 구현\n",
    "# 보상과 선택된 액션을 네트워크에 피드해줌으로써 비용을 계산하고\n",
    "# 비용을 이용해 네트워크를 업데이트\n",
    "reward_holder = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "action_holder = tf.placeholder(shape=[1], dtype=tf.int32)\n",
    "\n",
    "responsible_output = tf.slice(output, action_holder, [1])\n",
    "loss =-(tf.log(responsible_output)*reward_holder)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "update = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 Running reward for the 5 arms of the bandit: [-1, 0, 0, 0, 0]\n",
      " 200 Running reward for the 5 arms of the bandit: [-5, -4, 28, -10, 42]\n",
      " 400 Running reward for the 5 arms of the bandit: [-8, -6, 57, -16, 70]\n",
      " 600 Running reward for the 5 arms of the bandit: [-25, -1, 86, -25, 96]\n",
      " 800 Running reward for the 5 arms of the bandit: [-22, -1, 128, -21, 133]\n",
      "1000 Running reward for the 5 arms of the bandit: [-21, 8, 166, -19, 173]\n",
      "1200 Running reward for the 5 arms of the bandit: [-38, 6, 213, -29, 197]\n",
      "1400 Running reward for the 5 arms of the bandit: [-53, 15, 263, -33, 233]\n",
      "1600 Running reward for the 5 arms of the bandit: [-61, 14, 316, -41, 267]\n",
      "1800 Running reward for the 5 arms of the bandit: [-64, 9, 365, -48, 311]\n",
      "2000 Running reward for the 5 arms of the bandit: [-64, 12, 415, -48, 364]\n",
      "2200 Running reward for the 5 arms of the bandit: [-67, 20, 472, -51, 411]\n",
      "2400 Running reward for the 5 arms of the bandit: [-62, 18, 538, -58, 445]\n",
      "2600 Running reward for the 5 arms of the bandit: [-66, 25, 588, -69, 475]\n",
      "2800 Running reward for the 5 arms of the bandit: [-70, 36, 651, -75, 517]\n",
      "3000 Running reward for the 5 arms of the bandit: [-66, 39, 718, -81, 565]\n",
      "3200 Running reward for the 5 arms of the bandit: [-64, 42, 795, -81, 617]\n",
      "3400 Running reward for the 5 arms of the bandit: [-65, 53, 855, -83, 651]\n",
      "3600 Running reward for the 5 arms of the bandit: [-58, 60, 916, -92, 687]\n",
      "3800 Running reward for the 5 arms of the bandit: [-56, 62, 980, -94, 717]\n",
      "4000 Running reward for the 5 arms of the bandit: [-58, 63, 1046, -106, 758]\n",
      "4200 Running reward for the 5 arms of the bandit: [-58, 61, 1120, -107, 787]\n",
      "4400 Running reward for the 5 arms of the bandit: [-58, 64, 1202, -107, 828]\n",
      "4600 Running reward for the 5 arms of the bandit: [-57, 63, 1285, -108, 870]\n",
      "4800 Running reward for the 5 arms of the bandit: [-56, 66, 1354, -110, 917]\n",
      "\n",
      "The agent thinks arm 3 is the most promising...\n",
      "It was right!\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 학습\n",
    "# 에이전트를 학습시킬 총 에피소드의 수\n",
    "total_episodes = 5000\n",
    "# 밴딧 손잡이에 대한 점수판을 0으로 설정(두 가지 방법은 같은결과)\n",
    "total_reward = np.zeros(num_arms) # 방법1\n",
    "total_reward = [0, 0, 0, 0, 0] # 방법2\n",
    "\n",
    "# 초기화\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 텐서플로우 그래프 생성\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(total_episodes):\n",
    "        # 볼츠만 분포에 따라 액션 선택\n",
    "        actions = sess.run(output)\n",
    "        # softmax함수에 weights를 넣어 나온 결과값 중 하나를 선택, \n",
    "        # 결과값은 0에서 1사이의 값으로 주어지므로 확률과같은 역할\n",
    "        pick = np.random.choice(actions, p=actions)\n",
    "        action = np.argmax(actions == pick)\n",
    "        \n",
    "        # 밴딧 손잡이 중 하나를 선택함으로써 보상을 받는다.\n",
    "        reward = pullBandit(bandit_arms[action])\n",
    "        \n",
    "        # 네트워크 업데이트\n",
    "        _, resp, ww = sess.run([update, responsible_output, weights], feed_dict={reward_holder:[reward], action_holder:[action]})\n",
    "        \n",
    "        # 보상의 총계 업데이트\n",
    "        total_reward[action] += reward\n",
    "        if i % 200 == 0:\n",
    "            print(\"{:4d} Running reward for the \".format(i) + str(num_arms) + \" arms of the bandit: \" + str(total_reward))\n",
    "\n",
    "print(\"\\nThe agent thinks arm \" + str(np.argmax(ww)+1) + \" is the most promising...\")\n",
    "if np.argmax(ww) == np.argmax(-np.array(bandit_arms)):\n",
    "    print(\"It was right!\")\n",
    "else:\n",
    "    print(\"Sorry, It was wrong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
